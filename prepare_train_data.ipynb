{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c80514-7b15-4f1f-9ee5-bc71d75a1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import logging\n",
    "import torchaudio\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from encodec.utils import convert_audio\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from transformers import BertTokenizer\n",
    "from huggingface_hub import hf_hub_download\n",
    "from packaging import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24ac071-cf54-460d-9b58-6c40b2710570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done!\n"
     ]
    }
   ],
   "source": [
    "max_duration_sec = 15.12 # the maximum allowed duration in seconds\n",
    "hubert_tokenizer_path = 'data/models/hubert/tokenizer.pth'\n",
    "hubert_path = 'data/models/hubert/hubert.pt'\n",
    "device='cuda'\n",
    "\n",
    "# From https://github.com/gitmylo/bark-voice-cloning-HuBERT-quantizer\n",
    "from hubert.hubert_manager import HuBERTManager\n",
    "hubert_manager = HuBERTManager()\n",
    "from hubert.pre_kmeans_hubert import CustomHubert\n",
    "from hubert.customtokenizer import CustomTokenizer\n",
    "hubert_manager.make_sure_hubert_installed()\n",
    "hubert_manager.make_sure_tokenizer_installed()\n",
    "\n",
    "# Load the HuBERT model\n",
    "hubert_model = CustomHubert(checkpoint_path=hubert_path).to(device)\n",
    "hubert_model.eval()\n",
    "for param in hubert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Load the CustomTokenizer model\n",
    "hubert_tokenizer = CustomTokenizer.load_from_checkpoint(hubert_tokenizer_path).to(device)  # Automatically uses the right layers\n",
    "\n",
    "from bark.generation import load_codec_model\n",
    "codec_model = load_codec_model(use_gpu=True)\n",
    "codec_model.eval()\n",
    "for param in codec_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "def get_duration(wav, sr):\n",
    "    return wav.shape[1] / sr\n",
    "\n",
    "print('loading done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24433fb4-e7d6-4650-bae2-8b18bac27c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_WINDOW_SIZE = 1024\n",
    "\n",
    "MAX_SEMANTIC_LEN = 256\n",
    "\n",
    "SEMANTIC_RATE_HZ = 49.9\n",
    "SEMANTIC_VOCAB_SIZE = 10_000\n",
    "\n",
    "TEXT_ENCODING_OFFSET = 10_048\n",
    "SEMANTIC_PAD_TOKEN = 10_000\n",
    "TEXT_PAD_TOKEN = 129_595\n",
    "SEMANTIC_INFER_TOKEN = 129_599\n",
    "\n",
    "MAX_COARSE_LEN = 768\n",
    "\n",
    "SAMPLE_RATE = 24_000\n",
    "CHANNELS = 1\n",
    "\n",
    "COARSE_SEMANTIC_PAD_TOKEN = 12_048\n",
    "COARSE_INFER_TOKEN = 12_050\n",
    "\n",
    "CODEBOOK_SIZE = 1024\n",
    "N_COARSE_CODEBOOKS = 2\n",
    "N_FINE_CODEBOOKS = 8\n",
    "COARSE_RATE_HZ = 75\n",
    "\n",
    "# 格式为： wav_path|text\n",
    "path='/mnt/cephfs/hjh/train_record/tts/bark_with_voice_clone/test_data'\n",
    "train_path=f'{path}/wavpaths.txt'\n",
    "\n",
    "def load_filepaths_and_text(filename, split=\"|\"):\n",
    "    with open(filename, encoding='utf-8', errors='ignore') as f:\n",
    "        filepaths_and_text = [line.strip().split(split) for line in f]\n",
    "        base = os.path.dirname(filename)\n",
    "        for j in range(len(filepaths_and_text)):\n",
    "            filepaths_and_text[j][0] = os.path.join(base, filepaths_and_text[j][0])\n",
    "    return filepaths_and_text\n",
    "    \n",
    "valid_lines_train = []\n",
    "# convert wavs to semantic tokens\n",
    "for wav_path, txt in load_filepaths_and_text(train_path):\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    if not get_duration(wav, sr) > max_duration_sec:\n",
    "        valid_lines_train.append((wav_path, txt))\n",
    "    wav = convert_audio(wav, sr, SAMPLE_RATE, CHANNELS).to(device)\n",
    "\n",
    "    semantic_vectors = hubert_model.forward(wav, input_sample_hz=SAMPLE_RATE)\n",
    "    semantic_tokens = hubert_tokenizer.get_token(semantic_vectors)\n",
    "\n",
    "    # save semantic tokens\n",
    "    os.makedirs(os.path.join(path, 'tokens'), exist_ok=True)\n",
    "    semantic_tokens = semantic_tokens.cpu().numpy()\n",
    "\n",
    "    # Extract discrete codes from EnCodec\n",
    "    with torch.no_grad():\n",
    "        encoded_frames = codec_model.encode(wav.unsqueeze(0))\n",
    "    codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]\n",
    "\n",
    "    # move codes to cpu\n",
    "    codes = codes.cpu().numpy()\n",
    "\n",
    "    # save tokens\n",
    "    np.savez_compressed(os.path.join(path, 'tokens', os.path.basename(wav_path).replace('.wav', '.npz')), fine=codes, coarse=codes[:2, :], semantic=semantic_tokens)\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f71937-e877-4e0e-b188-63c45e600920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "valid_lines_valid = []\n",
    "\n",
    "valid_path=f'{path}/valid.txt'\n",
    "\n",
    "for wav_path, txt in load_filepaths_and_text(valid_path):\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    if not get_duration(wav, sr) > max_duration_sec:\n",
    "        valid_lines_valid.append((wav_path, txt))\n",
    "    wav = convert_audio(wav, sr, SAMPLE_RATE, CHANNELS).to(device)\n",
    "\n",
    "    semantic_vectors = hubert_model.forward(wav, input_sample_hz=SAMPLE_RATE)\n",
    "    semantic_tokens = hubert_tokenizer.get_token(semantic_vectors)\n",
    "\n",
    "    # save semantic tokens\n",
    "    os.makedirs(os.path.join(path, 'tokens'), exist_ok=True)\n",
    "    semantic_tokens = semantic_tokens.cpu().numpy()\n",
    "    \n",
    "    # Extract discrete codes from EnCodec\n",
    "    with torch.no_grad():\n",
    "        encoded_frames = codec_model.encode(wav.unsqueeze(0))\n",
    "    codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1).squeeze()  # [n_q, T]\n",
    "\n",
    "    # move codes to cpu\n",
    "    codes = codes.cpu().numpy()\n",
    "\n",
    "    # save tokens\n",
    "    np.savez_compressed(os.path.join(path, 'tokens', os.path.basename(wav_path).replace('.wav', '.npz')), fine=codes, coarse=codes[:2, :], semantic=semantic_tokens)\n",
    "\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0a6b1dd-13f1-4a55-b600-04355f5d997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del hubert_model\n",
    "# del hubert_tokenizer\n",
    "# del codec_model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad9354-4ace-4e77-8173-9333bc7d86d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
