{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import logging\n",
    "import torchaudio\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from encodec.utils import convert_audio\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from transformers import BertTokenizer\n",
    "from huggingface_hub import hf_hub_download\n",
    "from packaging import version\n",
    "from diffusers.optimization import get_scheduler\n",
    "\n",
    "from utils.bitsandbytes import BitsAndBytesConfig, importlib_metadata, get_keys_to_not_convert, replace_with_bnb_linear, set_module_quantized_tensor_to_device\n",
    "from utils.lora import convert_linear_layer_to_lora, only_optimize_lora_parameters, convert_lora_to_linear_layer\n",
    "from bark.model import GPTConfig, GPT\n",
    "from bark.model_fine import FineGPT, FineGPTConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "eval_batch_size = 8\n",
    "grad_accum = 2\n",
    "ckpt_path = 'models/fine_2.pt'\n",
    "model_type = \"fine\"\n",
    "dataset_path = 'datasets/joe_biden_state_of_union/'\n",
    "logging_dir = 'logs/'\n",
    "log_with = 'wandb'\n",
    "hubert_path = 'data/models/hubert/hubert.pt'\n",
    "hubert_tokenizer_path = 'data/models/hubert/tokenizer.pth'\n",
    "\n",
    "output_dir = 'fine_output/'\n",
    "resume_from_checkpoint = None\n",
    "\n",
    "checkpointing_steps = 1000\n",
    "\n",
    "mixed_precision = 'bf16'\n",
    "bits = 16 #4 4 and 8 bit are a work in progress\n",
    "compute_dtype = torch.bfloat16\n",
    "double_quant = True\n",
    "quant_type = 'nf4'\n",
    "\n",
    "lora_dim = 64\n",
    "lora_scaling = 1\n",
    "lora_dropout = 0.1\n",
    "lora_module_name = 'transformer.h'\n",
    "optimize_lora_params_only = False\n",
    "\n",
    "learning_rate = 1e-4\n",
    "scale_lr = False\n",
    "use_8bit_adam = False\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.999\n",
    "adam_epsilon = 1e-8\n",
    "weight_decay = 0.01\n",
    "\n",
    "llm_int8_skip_modules = None\n",
    "keep_in_fp32_modules = ['lm_head']\n",
    "\n",
    "lr_scheduler_type = 'linear'\n",
    "lr_warmup_steps = 60\n",
    "num_train_epochs = 5\n",
    "max_train_steps = None\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "seed = 741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bf16 mixed precision requires PyTorch >= 1.10 and a supported device.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 218\u001B[0m\n\u001B[1;32m    213\u001B[0m             fine_tokens\u001B[38;5;241m.\u001B[39mappend(fine_tokens_)\n\u001B[1;32m    215\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfine_tokens\u001B[39m\u001B[38;5;124m'\u001B[39m: torch\u001B[38;5;241m.\u001B[39mstack(fine_tokens)\u001B[38;5;241m.\u001B[39mcontiguous()}\n\u001B[0;32m--> 218\u001B[0m accelerator \u001B[38;5;241m=\u001B[39m \u001B[43mAccelerator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgradient_accumulation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_accum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmixed_precision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmixed_precision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_with\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_with\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproject_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogging_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m    224\u001B[0m device \u001B[38;5;241m=\u001B[39m accelerator\u001B[38;5;241m.\u001B[39mdevice\n\u001B[1;32m    226\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(output_dir, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda2/envs/bark/lib/python3.10/site-packages/accelerate/accelerator.py:460\u001B[0m, in \u001B[0;36mAccelerator.__init__\u001B[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, deepspeed_plugin, fsdp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, dispatch_batches, even_batches, use_seedable_sampler, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend)\u001B[0m\n\u001B[1;32m    458\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnative_amp \u001B[38;5;241m=\u001B[39m is_bf16_available(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    459\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mixed_precision \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbf16\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnative_amp \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_tpu_available():\n\u001B[0;32m--> 460\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err\u001B[38;5;241m.\u001B[39mformat(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbf16\u001B[39m\u001B[38;5;124m\"\u001B[39m, requirement\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPyTorch >= 1.10 and a supported device.\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    462\u001B[0m \u001B[38;5;66;03m# Start of internal step tracking\u001B[39;00m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mValueError\u001B[0m: bf16 mixed precision requires PyTorch >= 1.10 and a supported device."
     ]
    }
   ],
   "source": [
    "\n",
    "CONTEXT_WINDOW_SIZE = 1024\n",
    "\n",
    "MAX_SEMANTIC_LEN = 256\n",
    "\n",
    "SEMANTIC_RATE_HZ = 49.9\n",
    "SEMANTIC_VOCAB_SIZE = 10_000\n",
    "\n",
    "TEXT_ENCODING_OFFSET = 10_048\n",
    "SEMANTIC_PAD_TOKEN = 10_000\n",
    "TEXT_PAD_TOKEN = 129_595\n",
    "SEMANTIC_INFER_TOKEN = 129_599\n",
    "\n",
    "MAX_COARSE_LEN = 768\n",
    "\n",
    "SAMPLE_RATE = 24_000\n",
    "CHANNELS = 1\n",
    "\n",
    "COARSE_SEMANTIC_PAD_TOKEN = 12_048\n",
    "COARSE_INFER_TOKEN = 12_050\n",
    "\n",
    "CODEBOOK_SIZE = 1024\n",
    "N_COARSE_CODEBOOKS = 2\n",
    "N_FINE_CODEBOOKS = 8\n",
    "COARSE_RATE_HZ = 75\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "USE_SMALL_MODELS = os.environ.get(\"SERP_USE_SMALL_MODELS\", False)\n",
    "\n",
    "default_cache_dir = os.path.join(os.path.expanduser(\"~\"), \".cache\")\n",
    "CACHE_DIR = os.path.join(os.getenv(\"XDG_CACHE_HOME\", default_cache_dir), \"serp\", \"bark_v0\")\n",
    "\n",
    "\n",
    "\n",
    "def _clear_cuda_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "def _md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "\n",
    "def _download(from_hf_path, file_name, to_local_path):\n",
    "    to_local_path = to_local_path.replace(\"\\\\\", \"/\")\n",
    "    path = '/'.join(to_local_path.split(\"/\")[:-1])\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    hf_hub_download(repo_id=from_hf_path, filename=file_name, local_dir=path)\n",
    "    os.replace(os.path.join(path, file_name), to_local_path)\n",
    "\n",
    "\n",
    "def _tokenize(tokenizer, text):\n",
    "    return tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "\n",
    "def _detokenize(tokenizer, enc_text):\n",
    "    return tokenizer.decode(enc_text)\n",
    "\n",
    "\n",
    "def _normalize_whitespace(text):\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "REMOTE_MODEL_PATHS = {\n",
    "    \"text_small\": {\n",
    "        \"repo_id\": \"suno/bark\",\n",
    "        \"file_name\": \"text.pt\",\n",
    "        \"checksum\": \"b3e42bcbab23b688355cd44128c4cdd3\",\n",
    "    },\n",
    "    \"coarse_small\": {\n",
    "        \"repo_id\": \"suno/bark\",\n",
    "        \"file_name\": \"coarse.pt\",\n",
    "        \"checksum\": \"5fe964825e3b0321f9d5f3857b89194d\",\n",
    "    },\n",
    "    \"fine_small\": {\n",
    "        \"repo_id\": \"suno/bark\",\n",
    "        \"file_name\": \"fine.pt\",\n",
    "        \"checksum\": \"5428d1befe05be2ba32195496e58dc90\",\n",
    "    },\n",
    "    \"text\": {\n",
    "        \"repo_id\": \"suno/bark\",\n",
    "        \"file_name\": \"text_2.pt\",\n",
    "        \"checksum\": \"54afa89d65e318d4f5f80e8e8799026a\",\n",
    "    },\n",
    "    \"coarse\": {\n",
    "        \"repo_id\": \"suno/bark\",\n",
    "        \"file_name\": \"coarse_2.pt\",\n",
    "        \"checksum\": \"8a98094e5e3a255a5c9c0ab7efe8fd28\",\n",
    "    },\n",
    "    \"fine\": {\n",
    "        \"repo_id\": \"suno/bark\",\n",
    "        \"file_name\": \"fine_2.pt\",\n",
    "        \"checksum\": \"59d184ed44e3650774a2f0503a48a97b\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def _load_model(ckpt_path, device, use_small=False, model_type=\"text\"):\n",
    "    if model_type == \"text\":\n",
    "        ConfigClass = GPTConfig\n",
    "        ModelClass = GPT\n",
    "    elif model_type == \"coarse\":\n",
    "        ConfigClass = GPTConfig\n",
    "        ModelClass = GPT\n",
    "    elif model_type == \"fine\":\n",
    "        ConfigClass = FineGPTConfig\n",
    "        ModelClass = FineGPT\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    model_key = f\"{model_type}_small\" if use_small or USE_SMALL_MODELS else model_type\n",
    "    model_info = REMOTE_MODEL_PATHS[model_key]\n",
    "    if ckpt_path in [None, '']:\n",
    "        ckpt_path = os.path.join(CACHE_DIR, model_info[\"file_name\"])\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        logger.info(f\"{model_type} model not found, downloading into `{CACHE_DIR}`.\")\n",
    "        _download(model_info[\"repo_id\"], model_info[\"file_name\"], ckpt_path)\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    # this is a hack\n",
    "    model_args = checkpoint[\"model_args\"]\n",
    "    if \"input_vocab_size\" not in model_args:\n",
    "        model_args[\"input_vocab_size\"] = model_args[\"vocab_size\"]\n",
    "        model_args[\"output_vocab_size\"] = model_args[\"vocab_size\"]\n",
    "        del model_args[\"vocab_size\"]\n",
    "    gptconf = ConfigClass(**checkpoint[\"model_args\"])\n",
    "    model = ModelClass(gptconf)\n",
    "    state_dict = checkpoint[\"model\"]\n",
    "    # fixup checkpoint\n",
    "    unwanted_prefix = \"_orig_mod.\"\n",
    "    for k, v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix) :]] = state_dict.pop(k)\n",
    "    extra_keys = set(state_dict.keys()) - set(model.state_dict().keys())\n",
    "    extra_keys = set([k for k in extra_keys if not k.endswith(\".attn.bias\")])\n",
    "    missing_keys = set(model.state_dict().keys()) - set(state_dict.keys())\n",
    "    missing_keys = set([k for k in missing_keys if not k.endswith(\".attn.bias\")])\n",
    "    if len(extra_keys) != 0:\n",
    "        raise ValueError(f\"extra keys found: {extra_keys}\")\n",
    "    if len(missing_keys) != 0:\n",
    "        raise ValueError(f\"missing keys: {missing_keys}\")\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    n_params = model.get_num_params()\n",
    "    val_loss = checkpoint[\"best_val_loss\"].item()\n",
    "    print(f\"Loaded {model_type} model with {n_params} params, val_loss={val_loss:.4f}.\")\n",
    "    del checkpoint, state_dict\n",
    "    _clear_cuda_cache()\n",
    "    if model_type == \"text\":\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "        return model, tokenizer\n",
    "    return model\n",
    "\n",
    "\n",
    "def _flatten_codebooks(arr, offset_size=CODEBOOK_SIZE):\n",
    "    assert len(arr.shape) == 2\n",
    "    arr = arr.copy()\n",
    "    if offset_size is not None:\n",
    "        for n in range(1, arr.shape[0]):\n",
    "            arr[n, :] += offset_size * n\n",
    "    flat_arr = arr.ravel(\"F\")\n",
    "    return flat_arr\n",
    "\n",
    "\n",
    "def load_filepaths_and_text(filename, split=\"|\"):\n",
    "    with open(filename, encoding='utf-8', errors='ignore') as f:\n",
    "        filepaths_and_text = [line.strip().split(split) for line in f]\n",
    "        base = os.path.dirname(filename)\n",
    "        for j in range(len(filepaths_and_text)):\n",
    "            filepaths_and_text[j][0] = os.path.join(base, filepaths_and_text[j][0])\n",
    "    return filepaths_and_text\n",
    "\n",
    "\n",
    "class TtsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        self.path = os.path.dirname(opt['path'])\n",
    "        self.mode = opt['mode']\n",
    "        self.audiopaths_and_text = load_filepaths_and_text(os.path.join(opt['path'] , opt['mode'] + '.txt'))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audiopath_and_text = self.audiopaths_and_text[index]\n",
    "        audiopath = audiopath_and_text[0]\n",
    "\n",
    "        tokens = np.load(audiopath.replace('.wav', '.npz').replace('wavs', 'tokens'))\n",
    "        fine_tokens = tokens['fine']\n",
    "\n",
    "        return torch.from_numpy(fine_tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audiopaths_and_text)\n",
    "\n",
    "\n",
    "class TtsCollater():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, batch):\n",
    "        max_len = 1024\n",
    "        fine_tokens = []\n",
    "\n",
    "        for fine_tokens_ in batch:\n",
    "            if fine_tokens_.shape[1] > max_len:\n",
    "                start_idx = np.random.randint(0, fine_tokens_.shape[1] - max_len + 1)\n",
    "                fine_tokens_ = fine_tokens_[:, start_idx : start_idx + max_len]\n",
    "\n",
    "            pad_size = max_len - fine_tokens_.shape[1]\n",
    "            fine_tokens_ = F.pad(fine_tokens_, (0, pad_size), value=CODEBOOK_SIZE)\n",
    "\n",
    "            fine_tokens_ = fine_tokens_.T\n",
    "\n",
    "            fine_tokens.append(fine_tokens_)\n",
    "\n",
    "        return {'fine_tokens': torch.stack(fine_tokens).contiguous()}\n",
    "    \n",
    "\n",
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=grad_accum,\n",
    "    mixed_precision=mixed_precision,\n",
    "    log_with=log_with,\n",
    "    project_dir=logging_dir,\n",
    ")\n",
    "device = accelerator.device\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}